name: ${oc.env:MODULE_NAME, 'traffic-meter'}

parameters:
  frame:
    width: 1280
    height: 720
    padding:
      # Paddings are kept on the output frame
      keep: true
      left: 0
      right: 0
      # Padding size is 180px on the top of the frame
      top: 0
      bottom: 0
  output_frame:
#    codec: jpeg
    codec: raw-rgba
#    codec: h264
  draw_func:
    module: samples.age_gender_recognition.overlay
    # specify the drawfunc's python class from the module
    class_name: Overlay
    rendered_objects:
      yolov5face:
        face:
          bbox:
            border_color: '00FF00FF'  # Green
            background_color: '00000000'  # transparent
            thickness: 2
          label:
            # Note that the label format for Primary_Detector.Car objects
            # is overriden on a per object basis:
            # every car has the classifier result labels added on separate lines
            format: [ '{label} #{track_id}' ]
            position:
              # position options are TopLeftInside / TopLeftOutside / Center
              position: TopLeftOutside
              margin_x: 0
              margin_y: 0
  age_min: 0
  age_max: 101
  face_width: 112
  face_height: 112

pipeline:

  source:
    element: uridecodebin
    properties:
      uri: file:///data/test.mp4

  elements:

    # detector
    - element: nvinfer@complex_model
      name: yolov5face
      model:
#        remote:
#          url: s3://savant-data/models/yolov8m/yolov8m.zip
#          checksum_url: s3://savant-data/models/yolov8m/yolov8m.md5
#          parameters:
#            endpoint: https://eu-central-1.linodeobjects.com
#        format: custom
        format: onnx
        config_file: yolov5n-face.txt
        input:
          shape: [3, 640, 640]
        output:
          layer_names: [ 'output' ]
          converter:
            module: savant.converter.yolo_v5face
            class_name: YoloV5faceConverter
            kwargs:
              confidence_threshold: 0.6
              nms_iou_threshold: 0.5
          objects:
            - class_id: 0
              label: face
              selector:
                module: samples.age_gender_recognition.selector
                class_name: MinMaxSizeBBoxSelector
                kwargs:
                  min_width: 40
                  min_height: 40
          attributes:
            - name: landmarks
    # tracker
    - element: nvtracker
      properties:
        tracker-width: 640
        tracker-height: 640
        ll-lib-file: /opt/nvidia/deepstream/deepstream/lib/libnvds_nvmultiobjecttracker.so
        ll-config-file: ${oc.env:PROJECT_PATH}/samples/nvidia_car_classification/config_tracker_NvDCF_perf.yml
        enable_batch_process: 1
    - element: nvinfer@attribute_model
      name: age_gender
      model:
        format: onnx
        config_file: age_gender_mobilenet_v2_dynBatch_config.txt
        input:
          object: yolov5face.face
          preprocess_object_image:
            module: samples.age_gender_recognition.age_gender_preproc
            class_name: AgeGenderPreprocessingObjectImageGPU
        output:
          layer_names: [ 'age', 'gender' ]
          converter:
            module:  samples.age_gender_recognition.age_gender_converter
            class_name: AgeGenderConverter
          attributes:
            - name: age
            - name: gender

    # analytics element realized in custom pyfunc
    - element: pyfunc
      module: samples.age_gender_recognition.smoothing
      class_name: AgeGenderSmoothing
      kwargs:
        history_len: 24
