name: ${oc.env:MODULE_NAME, 'age-gender-recognition'}

parameters:
  frame:
    width: 1280
    height: 720
  output_frame:
    codec: raw-rgba
  draw_func:
    module: samples.age_gender_recognition.overlay
    # specify the drawfunc's python class from the module
    class_name: Overlay
    rendered_objects:
      yolov8nface:
        face:
          bbox:
            border_color: '00FF00FF'  # Green
            background_color: '00000000'  # transparent
            thickness: 2
          label:
            # Note that the label format for yolov8nface.face objects
            # is overriden on a per object basis:
            # every face has the age gender result labels added on separate lines
            format: [ '{label} #{track_id}' ]
            position:
              # position options are TopLeftInside / TopLeftOutside / Center
              position: TopLeftOutside
              margin_x: 0
              margin_y: 0
  age_min: 0
  age_max: 101
  face_width: 112
  face_height: 112
  detection_model_name: yolov8nface


pipeline:

  elements:

    # detector
    - element: nvinfer@complex_model
      name: ${parameters.detection_model_name}
      model:
        remote:
          url: s3://savant-data/models/yolov8face/${parameters.detection_model_name}.zip
          checksum_url: s3://savant-data/models/yolov8face/${parameters.detection_model_name}.md5
          parameters:
            endpoint: https://eu-central-1.linodeobjects.com
        format: onnx
        config_file: yolov8n-face.txt
        input:
          shape: [3, 640, 640]
        output:
          layer_names: [ 'output0' ]
          converter:
            module: savant.converter.yolo_v8face
            class_name: YoloV8faceConverter
            kwargs:
              confidence_threshold: 0.6
              nms_iou_threshold: 0.5
          objects:
            - class_id: 0
              label: face
              selector:
                module: savant.selector.detector
                class_name: MinMaxSizeBBoxSelector
                kwargs:
                  min_width: 40
                  min_height: 40
          attributes:
            - name: landmarks

    # tracker
    - element: nvtracker
      properties:
        tracker-width: 640
        tracker-height: 640
        ll-lib-file: /opt/nvidia/deepstream/deepstream/lib/libnvds_nvmultiobjecttracker.so
        ll-config-file: ${oc.env:PROJECT_PATH}/samples/age_gender_recognition/config_tracker_NvDCF_perf.yml

    # age-gender estimator
    - element: nvinfer@attribute_model
      name: age_gender
      model:
        remote:
          url: s3://savant-data/models/age_gender/age_gender.zip
          checksum_url: s3://savant-data/models/age_gender/age_gender.md5
          parameters:
            endpoint: https://eu-central-1.linodeobjects.com
        format: onnx
        config_file: age_gender_mobilenet_v2_dynBatch_config.txt
        input:
          object: ${parameters.detection_model_name}.face
          preprocess_object_image:
            module: samples.age_gender_recognition.age_gender_preproc
            class_name: AgeGenderPreprocessingObjectImageGPU
        output:
          layer_names: [ 'age', 'gender' ]
          converter:
            module:  samples.age_gender_recognition.age_gender_converter
            class_name: AgeGenderConverter
          attributes:
            - name: age
            - name: gender

    # analytics element realized in custom pyfunc
    - element: pyfunc
      module: samples.age_gender_recognition.smoothing
      class_name: AgeGenderSmoothing
      kwargs:
        history_len: 24
