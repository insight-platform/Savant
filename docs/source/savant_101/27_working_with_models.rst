Working With Models
===================

Deepstream inference backend requires model to be in one of the following formats:

#. ONNX
#. UFF
#. Caffe
#. Nvidia TAO toolkit
#. Custom CUDA engine

